{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f1fd20-52a2-46e1-92c2-7747626f36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, ast\n",
    "import openai\n",
    "from dotenv import load_dotenv  \n",
    "import os\n",
    "\n",
    "# 加载.env文件  \n",
    "load_dotenv(\"en1106.env\")  \n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = os.environ[\"Azure_OPENAI_API_TYPE1\"]\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"Azure_OPENAI_API_BASE1\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] =  os.environ[\"Azure_OPENAI_API_KEY1\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"Azure_OPENAI_API_VERSION1\"]\n",
    "BASE_URL=os.environ[\"OPENAI_API_BASE\"]\n",
    "API_KEY=os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "CHAT_DEPLOYMENT_NAME=os.environ.get('AZURE_OPENAI_API_CHAT_DEPLOYMENT_NAME')\n",
    "EMBEDDING_DEPLOYMENT_NAME=os.environ.get('AZURE_OPENAI_API_EMBEDDING_DEPLOYMENT_NAME')\n",
    "\n",
    "openai.api_type = os.environ[\"OPENAI_API_TYPE\"]\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# LLM\n",
    "import requests\n",
    "from urllib.parse import quote  \n",
    "  \n",
    "\n",
    "messages=[]\n",
    "system_message = {\"role\":\"system\",\"content\":'''You're python developer.And always create python function to resolve question\"\n",
    "    '''}\n",
    "max_times=5\n",
    "current_times=1\n",
    "\n",
    "def ask(prompt):\n",
    "    messages.append({ \"role\": \"user\",\"content\":prompt})\n",
    "    result = run_conversation()\n",
    "    print(result)\n",
    "\n",
    "def run_code(code_in_string,function_name,return_local_variable_name):\n",
    "    try:\n",
    "        print(f'{function_name} running...')\n",
    "        exec(code_in_string,globals(),locals())\n",
    "        return locals()[return_local_variable_name]\n",
    "    except Exception as e:\n",
    "        return f'error: {str(e)}'\n",
    "    \n",
    "def run_conversation():\n",
    "    global current_times,max_times\n",
    "    if current_times> max_times:\n",
    "        return \"Error running exceed the max loop times!\"\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    print(f'======run_conversation======')\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"run_code\",\n",
    "                \"description\": \"run python code\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                      \"code_in_string\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The python code function writen in string\"\n",
    "                      },\n",
    "                      \"function_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The python code function name\"\n",
    "                      },  \n",
    "                      \"return_local_variable_name\":{\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The python code return local variable name\"\n",
    "                      }\n",
    "                    },\n",
    "                    \"required\": [\"code_in_string\",\"function_name\",\"return_local_variable_name\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    print(messages)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-35-turbo-1106\",\n",
    "        messages = [system_message]+messages[-10:],\n",
    "        temperature=0.5,\n",
    "        max_tokens=800,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "        stream=True\n",
    "    )\n",
    "    ret=''\n",
    "    function_name=''\n",
    "    funArg=''\n",
    "    callId=None\n",
    "    for chunk in response:\n",
    "        #print(chunk)\n",
    "        if chunk.choices:\n",
    "            if 'content' in chunk.choices[0].delta:\n",
    "                c=chunk.choices[0].delta.content\n",
    "                ret+=c\n",
    "                \n",
    "            if \"tool_calls\" in chunk.choices[0].delta:\n",
    "                if 'id' in chunk.choices[0].delta.tool_calls[0]:\n",
    "                    callId=chunk.choices[0].delta.tool_calls[0].id\n",
    "                if 'function' in chunk.choices[0].delta.tool_calls[0]:\n",
    "                    if 'name' in chunk.choices[0].delta.tool_calls[0].function:\n",
    "                        function_name=chunk.choices[0].delta.tool_calls[0].function.name\n",
    "                    if 'arguments' in chunk.choices[0].delta.tool_calls[0].function:   \n",
    "                        funArg+=chunk.choices[0].delta.tool_calls[0].function.arguments\n",
    "                    \n",
    "                \n",
    "    if ret !='':\n",
    "        #print(ret)\n",
    "        messages.append({ \"role\": \"assistant\",\"content\":ret})\n",
    "        return ret\n",
    "\n",
    "    print(callId)\n",
    "    print(function_name)\n",
    "    print(funArg)\n",
    "    \n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if function_name !='':\n",
    "        assistant_reply={\n",
    "          \"role\": \"assistant\",\n",
    "          \"tool_calls\": [\n",
    "            {\n",
    "              \"id\":callId,\n",
    "              \"type\": \"function\",\n",
    "              \"function\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\":funArg\n",
    "              }\n",
    "            }\n",
    "          ],\n",
    "          \"content\":\"\"\n",
    "        }\n",
    "       \n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            run_code.__name__: run_code,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_args = json.loads(funArg)\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_response = function_to_call(**function_args)\n",
    "        \n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        messages.append(assistant_reply)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": callId,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": str(function_response) if function_response else '',\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        #step 5 verify result\n",
    "        with open(f'{function_args[\"function_name\"]}.py', \"w\") as file:\n",
    "            file.write(function_args[\"code_in_string\"])\n",
    "        current_times+=1\n",
    "        return run_conversation()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001ba0d3-5f82-4012-ad71-8bb5f8d14d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======run_conversation======\n",
      "[{'role': 'user', 'content': 'Hello!'}]\n",
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "ask(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8738bb-a548-41a1-a3fb-ba8bcdf36794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======run_conversation======\n",
      "[{'role': 'user', 'content': 'Hello!'}, {'role': 'assistant', 'content': 'Hi there! How can I assist you today?'}, {'role': 'user', 'content': '计算前10位斐波那契数列的和'}]\n",
      "call_JkJX5dCAngk9ExNg8Eu9mXUI\n",
      "run_code\n",
      "{\"code_in_string\":\"def fibonacci_sequence(n):\\n    fib = [0, 1]\\n    for i in range(2, n):\\n        fib.append(fib[i-1] + fib[i-2])\\n    return fib\\n\\nsequence = fibonacci_sequence(10)\\nsum_sequence = sum(sequence)\\nsum_sequence\",\"function_name\":\"fibonacci_sequence_sum\",\"return_local_variable_name\":\"sum_sequence\"}\n",
      "fibonacci_sequence_sum running...\n",
      "======run_conversation======\n",
      "[{'role': 'user', 'content': 'Hello!'}, {'role': 'assistant', 'content': 'Hi there! How can I assist you today?'}, {'role': 'user', 'content': '计算前10位斐波那契数列的和'}, {'role': 'assistant', 'tool_calls': [{'id': 'call_JkJX5dCAngk9ExNg8Eu9mXUI', 'type': 'function', 'function': {'name': 'run_code', 'arguments': '{\"code_in_string\":\"def fibonacci_sequence(n):\\\\n    fib = [0, 1]\\\\n    for i in range(2, n):\\\\n        fib.append(fib[i-1] + fib[i-2])\\\\n    return fib\\\\n\\\\nsequence = fibonacci_sequence(10)\\\\nsum_sequence = sum(sequence)\\\\nsum_sequence\",\"function_name\":\"fibonacci_sequence_sum\",\"return_local_variable_name\":\"sum_sequence\"}'}}], 'content': ''}, {'tool_call_id': 'call_JkJX5dCAngk9ExNg8Eu9mXUI', 'role': 'tool', 'name': 'run_code', 'content': '88'}]\n",
      "The sum of the first 10 Fibonacci numbers is 88.\n"
     ]
    }
   ],
   "source": [
    "ask(\"计算前10位斐波那契数列的和\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f52d0-f61d-4fe2-826d-be85d8882f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e5ac6-2595-469c-b8e7-e7ea33529a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
